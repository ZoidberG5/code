2024-12-28 01:52:08,960 - INFO - Application started
2024-12-28 01:52:18,273 - INFO - ----------GPU details----------
2024-12-28 01:52:18,273 - INFO - PyTorch version: 2.5.1+cu124
2024-12-28 01:52:18,274 - INFO - CUDA device: NVIDIA RTX 3500 Ada Generation Laptop GPU
2024-12-28 01:52:18,274 - INFO - Allocated GPU memory: 91933184 bytes
2024-12-28 01:52:18,274 - INFO - Cached GPU memory: 104857600 bytes
2024-12-28 01:52:18,274 - INFO - ----------Processing loop started----------
2024-12-28 01:52:18,274 - INFO - ----New round of detections----
2024-12-28 01:52:18,411 - CRITICAL - Critical error in while loop
Traceback (most recent call last):
  File "c:\Users\shai.y\Documents\Naggles_tmp-main\code\main_with_gui.py", line 233, in processing_loop
    results_r, frame_r = detector.detect_and_describe(frame=frames[1], save_images=config['SAVE_IMAGES'], camera_index=camera_indices[1])
  File "c:\Users\shai.y\Documents\Naggles_tmp-main\code\OOP_yolo_detector.py", line 55, in detect_and_describe
    results = self.model(frame_tensor, size=self.img_size)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\shai.y/.cache\torch\hub\ultralytics_yolov5_master\models\common.py", line 866, in forward
    return self.model(ims.to(p.device).type_as(p), augment=augment)  # inference
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\shai.y/.cache\torch\hub\ultralytics_yolov5_master\models\common.py", line 688, in forward
    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\shai.y/.cache\torch\hub\ultralytics_yolov5_master\models\yolo.py", line 270, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "C:\Users\shai.y/.cache\torch\hub\ultralytics_yolov5_master\models\yolo.py", line 169, in _forward_once
    x = m(x)  # run
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\shai.y\AppData\Roaming\Python\Python310\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\shai.y/.cache\torch\hub\ultralytics_yolov5_master\models\common.py", line 456, in forward
    return torch.cat(x, self.d)
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 136 but got size 135 for tensor number 1 in the list.
2024-12-28 01:52:18,414 - INFO - The video ended and now the App will be close! Bey Bey
